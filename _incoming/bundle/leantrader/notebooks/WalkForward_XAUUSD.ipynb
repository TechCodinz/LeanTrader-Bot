{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d73caf2",
   "metadata": {},
   "source": [
    "\n",
    "# LeanTrader — XAUUSD Walk-Forward Validation\n",
    "\n",
    "This notebook performs **walk-forward validation** on XAUUSD strategy parameters.\n",
    "\n",
    "- Splits historical data into **rolling training windows** and **test windows**.\n",
    "- For each split: runs a parameter sweep (ADX, ATR stop, R multiple, FVG lookback).\n",
    "- Selects best params from training → applies to test → records performance.\n",
    "- Reports average test Sharpe, MaxDD, and consistency.\n",
    "\n",
    "This prevents overfitting and ensures robustness across time periods & sessions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51d89c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, yaml, itertools\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from leantrader.data.feeds import get_ohlc_csv, resample_frames\n",
    "from leantrader.features.ta import rsi, adx, fvg_score\n",
    "from leantrader.dsl.compiler import compile_strategy, load_strategy\n",
    "from leantrader.backtest.engine import backtest\n",
    "from leantrader.backtest.metrics import sharpe, max_drawdown\n",
    "\n",
    "REPO_ROOT = Path.cwd().resolve()\n",
    "DATA_DIR = REPO_ROOT / \"data\" / \"ohlc\"\n",
    "PAIR = \"XAUUSD\"\n",
    "m15_path = DATA_DIR / f\"{PAIR}_M15.csv\"\n",
    "assert m15_path.exists(), f\"Missing {m15_path}\"\n",
    "df_m15 = get_ohlc_csv(str(m15_path))\n",
    "frames = resample_frames(df_m15)\n",
    "\n",
    "# Engineering with param\n",
    "def engineer_param(df: pd.DataFrame, fvg_lb: int = 3) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    out[\"rsi_14\"] = rsi(out[\"close\"], 14)\n",
    "    out[\"adx_14\"] = adx(out, 14)\n",
    "    out[\"fvg_score\"] = fvg_score(out, fvg_lb)\n",
    "    return out\n",
    "\n",
    "spec_path = REPO_ROOT / \"src\" / \"leantrader\" / \"dsl\" / \"examples\" / \"xauusd_master.yaml\"\n",
    "base_spec = load_strategy(str(spec_path))\n",
    "\n",
    "def spec_with_params(spec, adx_thr: int, atr_stop: float, r_mult: float):\n",
    "    import copy\n",
    "    s = copy.deepcopy(spec)\n",
    "    for sig in s.signals:\n",
    "        for cond in sig.entry:\n",
    "            if cond.feature.startswith(\"adx_14\"):\n",
    "                cond.feature = f\"adx_14 > {adx_thr}\"\n",
    "        sig.stop = f\"atr_14 * {atr_stop}\"\n",
    "        sig.take = f\"R:{r_mult}\"\n",
    "    return s\n",
    "\n",
    "param_space = {\n",
    "    \"adx_thr\": [18, 20, 22],\n",
    "    \"atr_stop\": [1.4, 1.6],\n",
    "    \"r_mult\": [2.0, 2.2],\n",
    "    \"fvg_lb\": [2, 3]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40df100",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "# Build walk-forward splits: 70% train, 30% test with rolling\n",
    "times = frames[\"M15\"].index\n",
    "n = len(times)\n",
    "window = int(n * 0.7)\n",
    "step = int(n * 0.1)\n",
    "\n",
    "splits = []\n",
    "for start in range(0, n-window, step):\n",
    "    train_idx = times[start:start+window]\n",
    "    test_idx = times[start+window:start+window+step]\n",
    "    if len(test_idx)==0: break\n",
    "    splits.append((train_idx, test_idx))\n",
    "\n",
    "print(\"Total splits:\", len(splits))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9e580f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "results = []\n",
    "for i,(train_idx, test_idx) in enumerate(splits):\n",
    "    best_train = None\n",
    "    best_score = -999\n",
    "    for adx_thr in param_space[\"adx_thr\"]:\n",
    "        for atr_stop in param_space[\"atr_stop\"]:\n",
    "            for r_mult in param_space[\"r_mult\"]:\n",
    "                for fvg_lb in param_space[\"fvg_lb\"]:\n",
    "                    eng = {k: engineer_param(v.loc[train_idx], fvg_lb=fvg_lb) for k,v in frames.items()}\n",
    "                    spec = spec_with_params(base_spec, adx_thr, atr_stop, r_mult)\n",
    "                    strat = compile_strategy(spec)\n",
    "                    sigs = strat(eng)\n",
    "                    m15 = eng[\"M15\"]\n",
    "                    sigs[\"price\"] = m15[\"close\"].reindex(sigs.index, method=\"ffill\")\n",
    "                    eq = backtest(m15, sigs, risk_cfg=None)\n",
    "                    if len(eq)==0: continue\n",
    "                    score = float(sharpe(eq)) - abs(float(max_drawdown(eq)))\n",
    "                    if score > best_score:\n",
    "                        best_score = score\n",
    "                        best_train = (adx_thr, atr_stop, r_mult, fvg_lb)\n",
    "    # test with best params\n",
    "    if best_train:\n",
    "        adx_thr, atr_stop, r_mult, fvg_lb = best_train\n",
    "        eng_test = {k: engineer_param(v.loc[test_idx], fvg_lb=fvg_lb) for k,v in frames.items()}\n",
    "        spec = spec_with_params(base_spec, adx_thr, atr_stop, r_mult)\n",
    "        strat = compile_strategy(spec)\n",
    "        sigs = strat(eng_test)\n",
    "        m15 = eng_test[\"M15\"]\n",
    "        sigs[\"price\"] = m15[\"close\"].reindex(sigs.index, method=\"ffill\")\n",
    "        eq = backtest(m15, sigs, risk_cfg=None)\n",
    "        if len(eq)>0:\n",
    "            results.append({\n",
    "                \"split\": i,\n",
    "                \"train_params\": best_train,\n",
    "                \"test_sharpe\": float(sharpe(eq)),\n",
    "                \"test_maxdd\": float(max_drawdown(eq))\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9959c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "res_df = pd.DataFrame(results)\n",
    "res_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39da9c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Aggregate performance across all test windows\n",
    "agg = res_df[[\"test_sharpe\",\"test_maxdd\"]].agg([\"mean\",\"std\",\"min\",\"max\"])\n",
    "agg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b5fb32",
   "metadata": {},
   "source": [
    "\n",
    "## Next\n",
    "- If test Sharpe is stable and MaxDD reasonable, deploy these params live.\n",
    "- If variance is high, expand parameter space or refine DSL logic.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
